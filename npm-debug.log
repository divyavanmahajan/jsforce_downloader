0 info it worked if it ends with ok
1 verbose cli [ '/usr/local/bin/node', '/usr/local/bin/npm', 'publish' ]
2 info using npm@3.5.4
3 info using node@v5.2.0
4 verbose publish [ '.' ]
5 silly cache add args [ '.', null ]
6 verbose cache add spec .
7 silly cache add parsed spec Result {
7 silly cache add   raw: '.',
7 silly cache add   scope: null,
7 silly cache add   name: null,
7 silly cache add   rawSpec: '.',
7 silly cache add   spec: '/Users/usd05813/Documents/2016/Salesforce/jsforce_downloader',
7 silly cache add   type: 'directory' }
8 verbose addLocalDirectory /Users/usd05813/.npm/jsforce_downloader/0.5.3/package.tgz not in flight; packing
9 info lifecycle jsforce_downloader@0.5.3~prepublish: jsforce_downloader@0.5.3
10 silly lifecycle jsforce_downloader@0.5.3~prepublish: no script for prepublish, continuing
11 verbose tar pack [ '/Users/usd05813/.npm/jsforce_downloader/0.5.3/package.tgz',
11 verbose tar pack   '/Users/usd05813/Documents/2016/Salesforce/jsforce_downloader' ]
12 verbose tarball /Users/usd05813/.npm/jsforce_downloader/0.5.3/package.tgz
13 verbose folder /Users/usd05813/Documents/2016/Salesforce/jsforce_downloader
14 verbose addLocalTarball adding from inside cache /Users/usd05813/.npm/jsforce_downloader/0.5.3/package.tgz
15 silly cache afterAdd jsforce_downloader@0.5.3
16 verbose afterAdd /Users/usd05813/.npm/jsforce_downloader/0.5.3/package/package.json not in flight; writing
17 verbose afterAdd /Users/usd05813/.npm/jsforce_downloader/0.5.3/package/package.json written
18 silly publish { name: 'jsforce_downloader',
18 silly publish   version: '0.5.3',
18 silly publish   description: 'Extract report data and report metadata from Salesforce. Download more than 2000 rows, asynchronously. Report is downloaded a day at a time with a standard date filter. It supports Tabular, Summary and Matrix reports. It can run in AWS Lambda and has built in support for sending the report data directly to S3. GZIP compression is supported for the output files.',
18 silly publish   main: 'index.js',
18 silly publish   scripts: { test: 'echo "Error: no test specified" && exit 1' },
18 silly publish   repository:
18 silly publish    { type: 'git',
18 silly publish      url: 'git//github.com/divyavanmahajan/jsforce_downloader.git' },
18 silly publish   keywords: [ 'Salesforce', 'report', 'downloader', 'jsforce' ],
18 silly publish   author:
18 silly publish    { name: 'Divya Mahajan',
18 silly publish      email: 'dvm@vanmahajan.com',
18 silly publish      url: 'http://vanmahajan.github.io' },
18 silly publish   bugs: { url: 'https://github.com/divyavanmahajan/jsforce_downloader/issues' },
18 silly publish   bin:
18 silly publish    { jsforce_downloader: './bin/jsforce_downloader',
18 silly publish      jsforce_s3_downloader: './bin/jsforce_s3_downloader',
18 silly publish      jsforce_downloader_metadata: './bin/jsforce_downloader_metadata' },
18 silly publish   license: 'ISC',
18 silly publish   dependencies:
18 silly publish    { jsforce: '*',
18 silly publish      'csv-stringify': '*',
18 silly publish      moment: '*',
18 silly publish      'moment-range': '*' },
18 silly publish   devDependencies: { chai: '^3.4.1', mocha: '^2.3.4' },
18 silly publish   readme: '# jsforce_downloader \n## by Divya van Mahajan\n\nExtract report data from Salesforce into a comma separated file. This package includes 4 components that can be used independently.\n- nodejs library to download Salesforce reports that have a date filter.\n- jsforce_downloader - command line utility to download Salesforce reports. (command line wrapper of the downloader).\n- jsforce_s3_downloader - command line utility to download Salesforce reports directly to S3.\n- jsforce_downloader_metadata - command line utility to display the metadata of a Salesforce report. Use this to inspect the fields and filters of a report. It also generates the SQL to create a table in MySQL to save this data.\n\n## Features\n- Download more than 2000 details rows.\n- Only extracts the detail rows (T!T) and ignores all group/summary sections.\n- Exported as a CSV with the displayed value and the underlying value.\n- Asynchronous reports are used to avoid the Salesforce limit on synchronous reports per hour.\n- Parallel downloads to speed up the extract.\n- Supports Tabular, Matrix and Summary report types.\n- Support for AWS Lambda. Run this downloader in AWS Lambda. A Lambda event handler is provided.\n- Support for AWS S3. Upload the downloaded data directly to S3 (no temp files needed on local machine).\n\nReport your issues or ask for feature requests at [Github Issues](https://github.com/divyavanmahajan/jsforce_downloader/issues).\n\n## How to install\nInstall jsforce_downloader and jsforce_downloader_metadata.\n```\n    npm install -g jsforce_downloader\n```\nOptionally - if you are using the AWS S3 feature, install the AWS SDK and set environment variables AWS_ACCESS_KEY, AWS_SECRET_KEY.\n```\n    npm install -g aws-sdk\n```    \n## Setup: Environment variables\nThe library and utilities rely on the environment variables to store the username and password. If you are writing your own nodejs program, you can pass these during initialization.\n```\n    SF_USER="myuseratsf@xyz.com"\n    SF_PASSWD_WITH_TOKEN="password";\n```\nIf you are saving the output to S3 (OUTPUTTO="s3"), you should set the following environment variables.\n```\n    AWS_ACCESS_KEY="access key id"\n    AWS_SECRET_KEY="secret for access key"\n```    \nThe security token is required since the app does not support OAuth sign in. \nTo get your security token, logon to Salesforce. \nAt the top navigation bar go to `your name > Setup > Personal Setup > My Personal Information > Reset My Security Token`.\nTo use your token, if your password is mypassword, and your security token is `XXXXXXXXXX`, then set `SF_PASSWD_WITH_TOKEN` to `mypasswordXXXXXXXXXX` to log in. \nIf you change your password, the security token is reset and sent to your email.\n\nMac OS X: Add the following lines to ~/.profile and restart Terminal.\n```sh\n    export SF_USER="myuser@sfdomain.com"\n    export SF_PASSWD_WITH_TOKEN="passwordTOKEN"\n```\nWindows:Follow the [instructions to set environment variables](http://www.computerhope.com/issues/ch000549.htm). \nRestart your command or Powershell window after you set the environment variables.\n\n## Command line tools: How to run jsforce_downloader_metadata\n\nThis will display all the metadata of a report. It includes details of columns and filters etc. \nEnsure you have set the environment variables for Salesforce `SF_USER="myuser@xyz.com"` and `SF_PASSWD_WITH_TOKEN="password";`.\n\nCommand: `jsforce_downloader_metadata {reportid}`\n\n    jsforce_downloader_metadata 00OE0000002wlroMAA\n\nThis creates the file `ReportMeta_00OE0000002wlroMAA.json`. The file has the JSON format metadata for the report - so you can easily find the index of the column to display, \n{Report Section of the Fact Map} and report filters. \nThe tool also creates a helper sql file `ReportSQL_00OE0000002wlroMAA.sql`. It contains the SQL commands for MySQL / Redshift to:\n+Create a table for this dataset\n+MYSQL insert SQL statement\n+MYSQL to load entire CSV into the table through SQL Workbench.\n+Redshift to copy S3 file into a table.\n+Redshift to copy S3 file into a table if you have compressed with GZIP.\n\n\n\n## Command line tools: How to run jsforce_downloader\nCommand line: To download a report\n\n`jsforce_downloader {reportid} {datefield} {index of field to display} {start date YYYY-MM-DD} {end date YYYY-MM-DD} [{MAX_Concurrent} [{Report section of the Fact Map}]]`\n\n\n### Preparation to download a report, you need\n+ The report ID (get this from the Salesforce URL when you open the report).    \n+ The name of the date field - e.g. Case.CreatedDate to slice up the report into daily chunks. This does not have to be in the report.\n+ The zero-based index of column that is displayed while extracting (helps you keep track of the progress.) If you aren\'t sure, use 0.\n+ The section of the report that you want to see. For a tabular report use "T!T". For others, see the next section (`Selecting the report section`).\n  \n  \nExample:\n```\n$ jsforce_downloader 00OE0000002wlroMAA Labor__c.CreatedDate 5 2016-01-01 2016-01-05 4 \'T!T\'\n    Starting here....\n    Report:00OE0000002wlroMAA\n    Output to:ReportOutput_00OE0000002wlroMAA_20160101_to_20160105_20160413134312\n    Start:2016-01-01\n    End:2016-05-01\n    Logged into Salesforce\n    username: sampleuser@sftest.com(Sample User)\n    Report name: Case Owner Email\n    0:Start Range: 2016-01-01T00:00:00-08:00 - 2016-01-01T23:59:59-08:00\n    1:Start Range: 2016-01-02T00:00:00-08:00 - 2016-01-02T23:59:59-08:00\n    ....\n    1:Returned Range: 2016-01-02T00:00:00-08:00 - 2016-01-02T23:59:59-08:00:Success\n    84 records\n    First: L-5156083 a0iE000000MiTNLIA3\n    Last : L-5156837 a0iE000000MiUMMIA3\n    Package size:83\n    ....\n    =============================\n    Report:00OE0000002wlroMAA\n    Date range:2016-01-01 to 2016-01-05\n    Output to:ReportOutput_00OE0000002wlroMAA_20160101_to_20160105_20160413134312\n    Done:1755 records written.\n    Async reports requested:5 - (succeeded:5,failed:0).\n```\n\nThis creates the file `ReportOutput_00OE0000002wlroMAA_20160101_to_20160105_20160413134312.csv`.\n\n### Selecting the report section\n The report section to extract is explained in the [Salesforce Analytics REST API guide](https://resources.docs.salesforce.com/sfdc/pdf/salesforce_analytics_rest_api.pdf) \n - in the section "`Decode the Fact Map`". The pattern for the fact map keys varies by report format as shown in this table.\n   Tabular    T!T: The grand total of a report. Both record data values and the grand total are represented by this key. \n   Summary    <First level row grouping_second level row grouping_third level row grouping>!T: T refers to the row grand total.\n   Matrix     <First level row grouping_second level row grouping>!<First level column grouping_second level column grouping>.\n   \nEach item in a row or column grouping is numbered starting with 0. Here are some examples of fact map keys:\n\n     0!T   | The first item in the first-level grouping.\n     1!T   | The second item in the first-level grouping.\n     0_0!T | The first item in the first-level grouping and the first item in the second-level grouping. \n     0_1!T | The first item in the first-level grouping and the second item in the second-level grouping. \n\n\n## Command line tools: How to run jsforce_s3_downloader\nTo download a report, you need\n\n`jsforce_s3_downloader {reportid} {datefield} {index of field to display} {start date YYYY-MM-DD} {end date YYYY-MM-DD} {s3 bucket} {s3 path} [{aws region}]`\n\nExample:\n\n```\n$ jsforce_s3_downloader 00OE0000002wlroMAA Labor__c.CreatedDate 5 2016-01-01 2016-01-04 monima test us-east-1\n    Switching AWS region to us-east-1\n    Starting here....\n    Report:00OE0000002wlroMAA\n    Output to:Upload to: s3://monima/test/ReportOut_00OE0000002wlroMAA_20160101-20160104_20160418030436.csv\n    Start:2016-01-01\n    ...\n    707 records\n    First row: (L-5158662,a0iE000000MiWcxIAF)\n    Last row : (L-5172382 a0iE000000MihGAIAZ)\n    =============================\n    Report       :00OE0000002wlroMAA\n    Date range   :2016-01-01 to 2016-01-04\n    Output to    :ReportOut_00OE0000002wlroMAA_20160101-20160104_20160418030436.csv\n    Done         :1087 records written.\n    Async reports:4 - (succeeded:4,failed:0).\n    Successfully uploaded data to s3://monima/monima/ReportOut_00OE0000002wlroMAA_20160101-20160104_20160418030436.csv\n```\nThis uploads the file `ReportOut_00OE0000002wlroMAA_20160101-20160104_20160418030436.csv` to the S3 bucket `monima`.\n\n## Using the library in your NodeJS program.\n\n\n#### Configuration of the library\nBefore you can use the report download function, you must initialize the library by calling jsforce_downloader.initialize.\n```javascript\n    var jsforce_downloader=require(\'jsforce_downloader\');\n    var config = {\n        MAX_CONCURRENT: 30, \n        // 30 parallel async report requests\n        \n        WAIT_BETWEEN_REQUESTS: 1000, \n        // 1000 milliseconds\n        \n        REPORTSECTION: "T!T", \n        // REPORTSECTION - The section of the report that you want to see. This is explained in the \n        // [Salesforce Analytics REST API guide](https://resources.docs.salesforce.com/sfdc/pdf/salesforce_analytics_rest_api.pdf) \n        // - in the section decode the Fact Map. \n        \n        WRITE_TEMP_FILES: !fs.existsSync(\'./tmp\'), \n        // Store output of each async report to the tmp subdirectory.\n        \n        SFOptions: {\n            loginUrl: "https://login.salesforce.com"\n        }, \n        // Initialization options for jsforce (see http://jsforce.github.io/jsforce/doc/Connection.html)\n        \n        SF_USER: process.env.SF_USER,\n        SF_PASSWD_WITH_TOKEN: process.env.SF_PASSWD_WITH_TOKEN,\n        \n        REPORTPREFIX: "ReportOut_",\n        // File name generated is REPORTPREFIX + reportid + startdate + enddate + execution timestamp\n        \n        OUTPUTTO: "file", \n        // This can be \'file\' - to write results to a file; or \'s3\' - to write results to a S3 object.\n        \n\n        GZIP: false,\n        // If set to true, this will use GZIP to compress the output file\n\n        AWSCONFIG: {    \n            accessKeyId: \'AKID\', secretAccessKey: \'SECRET\', region: \'us-west-2\'\n        }, \n        // This is required when you are using AWS S3 outside AWS Lambda and have not set the environment variables AWS_ACCESS_KEY and AWS_SECRET_KEY.  \n        // See http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/Config.html#constructor-property\n            \n        S3BUCKET: "", \n        // S3 bucket if OUTPUTTO is set to "s3".\n        \n        S3KEYPREFIX: "" \n        // S3 key prefix if OUTPUTTO is set to "s3". This is the path where you want to store the output file.\n    };\n    jsforce_downloader.initialize(config);\n    \n```\n#### Using the library\n\n`jsforce_downloader.downloadreport` : is the main function that downloads the report. The function returns a Javascript promise.\n\n```javascript\n/**\n * @param {String} _reportID - Salesforce report identifier. You can get this from the URL when you are viewing the report.\n * @param {String} _datefield - Internal name of the date field used in the standard date filter. \n * @param {String} _indexfieldOffset - Column that should be displayed while running the report (starts at 0). By default the first column is shown.\n * @param {Date} _startDate - Starting date in the format YYYY-MM-DD.\n * @param {Date} _endDate - Ending date in the format YYYY-MM-DD.\n * @param {String} _user - username.\n * @param {String} _password - password with security token.\n */\n ```\n \n Example:\n \n```javascript\n    jsforce_downloader.downloadreport(report, "Datefield", options.indexfield, options.startdate, options.enddate).then(\n        function(res) {\n            console.log(jsforce_downloader.s3outputkey);\n            if (typeof callback == "function") {\n                callback(null, jsforce_downloader.s3outputkey);\n            }\n        }, function(err) {\n            console.error(err);\n            if (typeof callback == "function") {\n                callback(err, null);\n            }\n\n        });\n```\n#### Other helpful exports\n\n`config`         | Config for the module.\n`s3outputkey`    | S3 URL if output is to S3.\n`result`         | CSV data set on success.\n`reportName`     | Name of the report from the metadata.\n`reportDescribe` | JSON metadata returned by report.describe()\n`reportRows`     | Number of rows exported.\n\n\n## Using it in AWS Lambda\nTo run the downloader in AWS Lambda, you need to create a lambda zip package. \nIf you have compiled node libraries, prepare this on a Linux machine.\n\n+ Prepare your environment.\n    + Create an empty directory.\n    + Install aws-sdk and jsforce_downloader.\n+ Create your lambda NodeJS script.\n+ Test your lambda function locally.\n+ Packaging the lambda function (creating a zip file for your AWS Lambda function).\n+ Create the Lambda function with the AWS CLI.\n+ Invoke the Lambda function with the AWS CLI.\n\n#### Create your lambda NodeJS script.\n\n```\nmkdir myfunction\ncd myfunction\nnpm install aws-sdk jsforce_downloader\ncurl -O https://raw.githubusercontent.com/divyavanmahajan/jsforce_downloader/master/lambda/index.js\ncurl -O https://raw.githubusercontent.com/divyavanmahajan/jsforce_downloader/master/lambda/test.js\ncurl -O https://raw.githubusercontent.com/divyavanmahajan/jsforce_downloader/master/lambda/event.json\ncurl -O https://raw.githubusercontent.com/divyavanmahajan/jsforce_downloader/master/lambda/makelambda.sh\ncurl -O https://raw.githubusercontent.com/divyavanmahajan/jsforce_downloader/master/lambda/invokelambda.sh\n\n```\n\n+ View [index.js](https://raw.githubusercontent.com/divyavanmahajan/jsforce_downloader/master/lambda/index.js) .\n+ View [test.js](https://raw.githubusercontent.com/divyavanmahajan/jsforce_downloader/master/lambda/test.js).\n\n#### Create the event for your lambda function.\n\n+ Edit the event file in the `myfunction` directory. \n+ Set your Salesforce and AWS details. `SF_USER`, `SF_PASSWD_WITH_TOKEN`, `S3BUCKET`, `S3KEYPREFIX`.\n+ Set the compression option `GZIP` to `true` or `false`.\n+ Set the report options. `report`, `datefield`, `indexfield`, `startdate`, `enddate`.\n\nAlternatively download and edit [event.json](https://raw.githubusercontent.com/divyavanmahajan/jsforce_downloader/master/lambda/event.json).\n\n```javascript\n{\n        "config":{\n                "MAX_CONCURRENT": 40,\n                "WAIT_BETWEEN_REQUESTS":500,\n                "REPORTSECTION": "T!T",\n                "WRITE_TEMP_FILES": false,\n                "SFOptions" : {\n                        "loginUrl": "https://login.salesforce.com"\n                },\n                "AWSCONFIG": {    \n                        "region": "us-east-1"\n                },\n                "SF_USER" : "sfuser@sfuser.com",\n                "SF_PASSWD_WITH_TOKEN": "passwd_and_token",\n                "REPORTPREFIX": "LambdaReportOut_",\n                "OUTPUTTO": "s3",\n                "GZIP":false,\n                "S3BUCKET": "monima",\n                "S3KEYPREFIX":"jsforce"\n\n        },\n        "options":{\n                "report": "_salesforce_reportid_like_00OE0000002qhwz",\n                "datefield": "Case.CreatedDate",\n                "indexfield": 0,\n                "startdate":"2016-04-13",\n                "enddate":"2016-04-15"\n        }\n}\n```\n\n#### Test your lambda function locally.\n+ Ensure the environment variables `AWS_ACCESS_KEY` and `AWS_SECRET_KEY` are set to your AWS credentials.\n+ Run `node test.js` to test the lambda function locally.\n+ Verify the file was successfully uploaded into S3.\n\n```sh\n$ node test.js\nStarting here....\nReport:00OE0000002whwz\nUpload to:s3://monima/jsforce/LambdaReportOut_00OE0000002whwz_20160413-20160413_20160417220418.csv\nStart:2016-04-13\nEnd:2016-04-15\nLogged into Salesforce\nusername: myuser@sf.com (My user)\n0:Start Range: (2016-04-13 to 2016-04-13)\n1:Start Range: (2016-04-14 to 2016-04-14)\n2:Start Range: (2016-04-15 to 2016-04-15)\n1:Returned Range: (2016-04-14 to 2016-04-14) :Success:413 rows in section T!T\n413 records\n...\n=============================\nReport       :00OE0000002whwz\nDate range   :2016-04-13 to 2016-04-15\nOutput to    :LambdaReportOut_00OE0000002whwz_20160413-20160415_20160417220418.csv\nDone         :1232 records written.\nAsync reports:3 - (succeeded:3,failed:0).\nSuccessfully uploaded data to s3://monima/jsforce/LambdaReportOut_00OE0000002whwz_20160413-20160415_20160417220418.csv\n```\n\n#### Setup AWS CLI\n+ Setup your AWS CLI if you want to use the command line to create your lambda function. \nIf you want to use the Web console, you don\'t need the AWS CLI. [Instructions for CLI setup](http://docs.aws.amazon.com/lambda/latest/dg/setup-awscli.html).\n\n#### Packaging and creating the lambda function\nEdit the `makelambda.sh` script in the `myfunction` directory. Correct the values for `LAMBDAFN`, `ARN`, `EVENTFILE` and `AWSPROFILE`.\n+ `ARN` - Get the ARN for the Lambda role "lambda_basic_execution" or "lambda_basic_execution_with_vpc".\n[IAM Home](https://console.aws.amazon.com/iam/home). View the details of the role and copy down its ARN. \nIt would look similar to `arn:aws:iam::854421518417:role/lambda_basic_execution`. \n+ `LAMBDAFN` - Choose a valid name for your Lambda function. \n+ `AWSPROFILE` - Set this to the correct "profilename" that you setup during the AWS CLI setup. If you don\'t remember try checking the file `~/.aws/credentials`.\n\nScript [makelambda.sh](https://raw.githubusercontent.com/divyavanmahajan/jsforce_downloader/master/lambda/makelambda.sh).\n```\n#!/bin/sh\nARN=arn:aws:iam::852391518417:role/lambda_basic_execution\nLAMBDAFN=DownloadSFReport\nAWSPROFILE=adminuser\n\necho -- 1. Make function.zip --\nrm function.zip\nzip -rq function index.js node_modules -x node_modules/aws-sdk/*\\* -x node_modules/jsforce/build/*\\* -x node_modules/jsforce/test/*\\*\n\necho -- 2. Delete Function $LAMBDAFN --\naws lambda delete-function \\\n--region us-east-1 \\\n--function-name $LAMBDAFN \\\n--profile $AWSPROFILE\n\necho -- 3. Create AWS Lambda function $LAMBDAFN with function.zip --\naws lambda create-function \\\n--region us-east-1 \\\n--function-name $LAMBDAFN \\\n--zip-file fileb://./function.zip \\\n--role $ARN \\\n--handler index.handler \\\n--runtime nodejs4.3 \\\n--profile $AWSPROFILE \\\n--timeout 300 \\\n--memory-size 512\n```\n\n+ 1 - This will create a ZIP file for your lambda function and exclude the test.js file which has your credentials.\n+ 2 - Deletes the old version if it exists.\n+ 3 - Create a lambda function running under the role selected above with 300 seconds timeout, \nNodeJS 4.3 runtime, 512 MB memory with function.zip for source code.\n\nExample:\n```\n$ sh ./makelambda.sh\n    -- 1. Make function.zip --\n    rm: function.zip: No such file or directory\n    -- 2. Delete Function DownloadSFReport --\n    -- 3. Create AWS Lambda function DownloadSFReport with function.zip --\n    {\n        "CodeSha256": "jQZ69IvYfpyX6w7KnMkyFCytdXba+rCLOeTd2P7Qg4c=", \n        "FunctionName": "DownloadSFReport", \n        "CodeSize": 4016351, \n        "MemorySize": 512, \n        "FunctionArn": "arn:aws:lambda:us-east-1:852391518417:function:DownloadSFReport", \n        "Version": "$LATEST", \n        "Role": "arn:aws:iam::852391518417:role/lambda_basic_execution", \n        "Timeout": 300, \n        "LastModified": "2016-04-18T21:48:36.966+0000", \n        "Handler": "index.handler", \n        "Runtime": "nodejs4.3", \n        "Description": ""\n    }\n```\n\n\n[Amazon docs on creating a Lambda function](http://docs.aws.amazon.com/lambda/latest/dg/with-userapp-walkthrough-custom-events-upload.html).\n\n\n#### Invoke the Lambda function\nEdit the `invokelambda.sh` script in the `myfunction` directory. Correct the values for `LAMBDAFN`, `ARN`, `EVENTFILE` and `AWSPROFILE`.\n+ `LAMBDAFN` - Choose a valid name for your Lambda function. \n+ `EVENTFILE` - We will reuse the event.json that you edited earlier. Check that it is valid JSON (all keys and values are quoted). [JSON Lint](jsonlint.com) is a quick and easy way to check the validity.\n+ `AWSPROFILE` - Set this to the correct "profilename" that you setup during the AWS CLI setup. If you don\'t remember try checking the file `~/.aws/credentials`.\n\nScript [invokelambda.sh](https://raw.githubusercontent.com/divyavanmahajan/jsforce_downloader/master/lambda/invokelambda.sh).\n```sh\n#!/bin/sh\nLAMBDAFN=DownloadSFReport\nEVENTFILE=./event.json\nAWSPROFILE=adminuser\n\necho -- 4. Invoke $LAMBDAFN with event.json --\naws lambda invoke \\\n--invocation-type RequestResponse \\\n--function-name $LAMBDAFN \\\n--region us-east-1 \\\n--log-type Tail \\\n--payload file://$EVENTFILE \\\n--profile $AWSPROFILE \\\noutputfile.txt\n```\n\nRun the script to invoke the function.\n\n```\n$ sh ./invokelambda.sh\n    -- 4. Invoke DownloadSFReport with event.json --\n    {\n        "LogResult": "base64-encoded-log-data", \n        "StatusCode": 200\n    }\n```\n\nThe logresult data in the response is `base64-encoded`. On Linux and Mac, you can use the base64 command to decode the log. \n```\n$ echo base64-encoded-log-data | base64 --decode\n    START RequestId: 231b8ce2-051c-11e6-84c3-af7b2d0cd02a Version: $LATEST\n    2016-04-18T04:15:10.683Z\t231b8ce2-051c-11e6-84c3-af7b2d0cd02a\tReport:00OE0000002whwz\n    2016-04-18T04:15:10.684Z\t231b8ce2-051c-11e6-84c3-af7b2d0cd02a\tOutput to:LambdaReportOut_00OE0000002whwz_20160413-20160415_20160418040466.csv\n    ...\n    2016-04-18T04:15:13.718Z\t231b8ce2-051c-11e6-84c3-af7b2d0cd02a\tSuccessfully uploaded data to s3://monima/jsforce/LambdaReportOut_00OE0000002whwz_20160413-20160415_20160418040466.csv\n    END RequestId: 231b8ce2-051c-11e6-84c3-af7b2d0cd02a\n    REPORT RequestId: 231b8ce2-051c-11e6-84c3-af7b2d0cd02a\tDuration: 3218.25 ms\tBilled Duration: 3300 ms \tMemory Size: 1024 MB\tMax Memory Used: 79 MB\n```\n\n### AWS errors and the workarounds\n\n+ `[PermanentRedirect: The bucket you are attempting to access must be addressed using the specified endpoint.` \nYou must specify a region to access your S3 bucket. Add this to your event.config or config.\n```\n    "AWSCONFIG": {\n        "region": \'us-east-1\'\n    },\n``` \n\n+ `Function was terminated` or `Function seems to be stuck`.\nLambda has a max timeout of 5 minutes and will terminate the function after that. \nCheck the max memory used for your stuck function, and increase it if you are at the limit.\n\n\n## Library inner working\nThe library does the following\n+ Download the report metadata to setup the headers for the CSV file. I use the excellent node library csv-stringify to create CSV files.\n+ Add a date filter to the report metadata.\n+ Request execution of an Async report where the date filter is set to each day between the start and end dates. So if there are 365 days between the start and end date, it will generate 365 async reports.\n+ The Async reports are requested in sets of 30 each. This can be changed by setting MAX_CONCURRENT in the config.\n+ The program starts polling Salesforce to see if the Async reports are finished. The polling is done every 2000 ms. This can be changed by setting WAIT_BETWEEN_REQUESTS in the config. I don\'t recommend a number less than 500 ms.\n+ Download the results of the completed Async reports and store them in memory.\n+ When all async reports are completed, output to a file or to a S3 object.\n\n### Design choices\nSF Async reports vs Sync reports: Async reports have a higher limit on the number of requests. This is important if you are downloading a lot of days.\n<< TODO: What is the limit of ASync reports per hour per user? >>\n\n\n### Why this library?\nI needed to automate the download of a large report to a CSV file. This task was done manually earlier and would take a long time to complete. So I looked into options using Node.\n\nThe excellent [jsForce](https://www.npmjs.com/package/jsforce) node module is a great wrapper around the Salesforce REST API. However it does not have a simple way to repeatedly call a report to get more than 2000 results. Unlike SOQL queries, there is no "queryMore" equivalent for reports. So I had to write a lot of non-trivial code to call the same report multiple times, switch to using asynchronous Salesforce reports, run multiple reports in parallel, etc. \n\nAfter the first revision went out, I got requests to make this run in AWS Lambda and export the data to AWS S3 directly. This allows it to be a part of a AWS Data Pipeline to automate loading Salesforce report extracts into AWS RedShift.\n\n\n\n',
18 silly publish   readmeFilename: 'README.md',
18 silly publish   gitHead: '7509542de9fbdb7bd96565de9d2bc9a281f35dbd',
18 silly publish   _id: 'jsforce_downloader@0.5.3',
18 silly publish   _shasum: 'cc029000a5d69e8529d94c98c6be7a52835e40d1',
18 silly publish   _from: '.' }
19 verbose getPublishConfig undefined
20 silly mapToRegistry name jsforce_downloader
21 silly mapToRegistry using default registry
22 silly mapToRegistry registry https://registry.npmjs.org/
23 silly mapToRegistry uri https://registry.npmjs.org/jsforce_downloader
24 verbose publish registryBase https://registry.npmjs.org/
25 silly publish uploading /Users/usd05813/.npm/jsforce_downloader/0.5.3/package.tgz
26 verbose request uri https://registry.npmjs.org/jsforce_downloader
27 verbose request sending authorization for write operation
28 info attempt registry request try #1 at 7:54:36 AM
29 verbose request using bearer token for auth
30 verbose request id ec4e47fbf8f75e20
31 http request PUT https://registry.npmjs.org/jsforce_downloader
32 http 403 https://registry.npmjs.org/jsforce_downloader
33 verbose headers { 'content-type': 'application/json',
33 verbose headers   'cache-control': 'max-age=300',
33 verbose headers   'content-length': '95',
33 verbose headers   'accept-ranges': 'bytes',
33 verbose headers   date: 'Tue, 19 Apr 2016 14:54:38 GMT',
33 verbose headers   via: '1.1 varnish',
33 verbose headers   connection: 'keep-alive',
33 verbose headers   'x-served-by': 'cache-sjc3124-SJC',
33 verbose headers   'x-cache': 'MISS',
33 verbose headers   'x-cache-hits': '0',
33 verbose headers   'x-timer': 'S1461077677.249695,VS0,VE960',
33 verbose headers   vary: 'Accept-Encoding' }
34 verbose request invalidating /Users/usd05813/.npm/registry.npmjs.org/jsforce_downloader on PUT
35 error publish Failed PUT 403
36 verbose stack Error: "You cannot publish over the previously published version 0.5.3." : jsforce_downloader
36 verbose stack     at makeError (/usr/local/lib/node_modules/npm/node_modules/npm-registry-client/lib/request.js:264:12)
36 verbose stack     at CachingRegistryClient.<anonymous> (/usr/local/lib/node_modules/npm/node_modules/npm-registry-client/lib/request.js:252:14)
36 verbose stack     at Request._callback (/usr/local/lib/node_modules/npm/node_modules/npm-registry-client/lib/request.js:172:14)
36 verbose stack     at Request.self.callback (/usr/local/lib/node_modules/npm/node_modules/request/request.js:198:22)
36 verbose stack     at emitTwo (events.js:88:13)
36 verbose stack     at Request.emit (events.js:173:7)
36 verbose stack     at Request.<anonymous> (/usr/local/lib/node_modules/npm/node_modules/request/request.js:1035:10)
36 verbose stack     at emitOne (events.js:83:20)
36 verbose stack     at Request.emit (events.js:170:7)
36 verbose stack     at IncomingMessage.<anonymous> (/usr/local/lib/node_modules/npm/node_modules/request/request.js:962:12)
37 verbose statusCode 403
38 verbose pkgid jsforce_downloader
39 verbose cwd /Users/usd05813/Documents/2016/Salesforce/jsforce_downloader
40 error Darwin 15.4.0
41 error argv "/usr/local/bin/node" "/usr/local/bin/npm" "publish"
42 error node v5.2.0
43 error npm  v3.5.4
44 error code E403
45 error "You cannot publish over the previously published version 0.5.3." : jsforce_downloader
46 error If you need help, you may report this error at:
46 error     <https://github.com/npm/npm/issues>
47 verbose exit [ 1, true ]
